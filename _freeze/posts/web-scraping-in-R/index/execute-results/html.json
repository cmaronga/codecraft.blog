{
  "hash": "0577208f9aa73b549dd91e6b2fe55891",
  "result": {
    "markdown": "---\ntitle: \"Web scraping using R\"\n# author: \"Christopher Maronga\"\ndate: \"2023-10-31\"\ncategories: [Data mining, Data wrangling, tidyverse]\nimage: \"web-scraping.jpeg\"\n# draft: true\n---\n\n\nEfficient, flexible and powerful!\n\n# Introduction\n\nWeb scraping is concept that most probably you have heard about. This is the art of [harvesting](https://en.wikipedia.org/wiki/Web_scraping) publicly available data from a website for use in your analysis or reporting. Web scraping can be as simple as copying the contents of a website and pasting them on an excel sheet, but thatâ€™s not what we are going to do today. Most website pages are built using [HTML](https://en.wikipedia.org/wiki/HTML) and this allows us to use tools such as R to dynamically extract the data.\n\nIn this tutorial, I am going walk you through how you can harvest data from websites using R programming language. You can do this by coding the logic and instructions manually or use the package [`{rvest}`](https://rvest.tidyverse.org/) to easily extract the contents of a website. We would demonstrate the examples using the below two websites.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading packages\npacman::p_load(\n  rvest,\n  ggthemes,\n  lubridate,\n  here,\n  tidyverse\n)\n```\n:::\n\n\n\n\n## Dollar exchange data\n\nI came across this website [Exchange rate to USD by country](https://www.theglobaleconomy.com/rankings/Dollar_exchange_rate/) while I was working on aggregating output from an[ economic micro-simulation model](https://asbmr.onlinelibrary.wiley.com/doi/full/10.1002/jbmr.4775?af=R) estimating benefits and budget impact of setting up fracture liaison services. Part of my reporting costs associated with the FLS, reported in local currency for about 10 different countries, but for harmonized reporting and international consumption, I need to convert the local currencies to US Dollars, hence I needed a source that I could cite and is updated regularly.\n\n\n### using `rvest`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get url from website\nexchange_rate_url <- \"https://www.theglobaleconomy.com/rankings/Dollar_exchange_rate/\"\n\n# read HTML from website\nexchange_rate_webpage <- read_html(exchange_rate_url)       # read html site\n\n\n# create a datframe containing the exchange rates for use\ncurrency_rates <- exchange_rate_webpage %>%\n  html_table() %>%                                          # output a list contain the exchange rate table from website\n  as.data.frame() %>%                                       # transform into a tibble\n  # rename columns appropriately\n  rename(\n    Country        = Countries,\n    LatestData     = \"Reference.date\",\n    LatesValue     = \"Latest.available.value\",\n    Change3months  = \"Change.three.months\",\n    Change12months = \"Change.twelve.months\"\n  ) %>%\n  mutate(across(LatesValue, as.numeric),                  # convert to numeric column containing exchange rate\n         \n         # On the date column; remove white space and replace \"/\" with \"-\"\n         LatestData = str_squish(\n           str_replace_all(\n             string = LatestData,\n             pattern = \"/\",\n             replacement = \"-\"\n           )\n         )) %>% \n  # transform `LatestData` into a proper date column\n  mutate(\n    LatestData = my(LatestData),                       # proper date format\n    LatestData = format(LatestData, \"%Y-%m\")           # YYYY-mm\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Export the data\n\nrio::export(currency_rates, here(\"datasets\", \"dollar_exchange_rates.rds\"))\n```\n:::\n\n\n\n\n\n\n### Using `readLines()`\n\n\n::: {.cell}\n\n:::\n\n\n\n## Available CRAN packages\n\n### CRAN packages by date\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specifying the url\nurl <- 'https://cran.r-project.org/web/packages/available_packages_by_date.html'\n\n\n# create a dataframe using `rvest` functions\nr_pkgs_by_date <- read_html(url) %>% \n  html_table() %>% \n  as.data.frame() %>% \n  mutate(\n    Date = ymd(Date)\n  ) %>% \n  rename(pkg_name = Package)\n```\n:::\n\n\n### CRAN packages metadata\n\nIf I need additional details, I can use the function xxxxx; downside, it doesn't contain date of publication but some other metrics which are equally important.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\navailable_pks <- available.packages(#repos = \"http://cran.us.r-project.org\",\n                                                                            # specify CRAN mirroe and metadata to extract\n  repos = \"https://cran.r-project.org/\")[, c(\"Version\",\n                                             \"Depends\",\n                                             \"Repository\",\n                                             \"NeedsCompilation\",\n                                             \"License\")] %>%\n  as.data.frame() %>% tibble::rownames_to_column(var = \"pkg_name\")\n```\n:::\n\n\n\n### CRAN packages downloads\n\nWe can grab metric on number of downloads for each package in CRAN for this website xxx\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npkg_down_url <- \"https://www.datasciencemeta.com/rpackages\"\n\npkg_downloads <- read_html(pkg_down_url) %>% \n  html_table() %>% \n  as.data.frame() %>% \n  select(-c(Author, Maintainer)) %>%                          # remove columns with no data\n  mutate(\n    Downloads = str_remove_all(Downloads, pattern = \",\"),     # get rid of commas\n    Downloads = as.integer(Downloads)                         # convert into an integer\n  ) %>% \n  rename(pkg_name = \"Package.Name\")\n```\n:::\n\n\n\n\nWe can now join all the three datasets telling different aspects of the packages to have one dataframe we can use for visualization and expropriationðŸ™‚\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCRAN_pkgs <- reduce(\n  list(r_pkgs_by_date, pkg_downloads, available_pks),\n  left_join,\n  by = \"pkg_name\"\n) %>% arrange(Rank) %>% \n  select(Rank, pkg_name, Downloads, everything())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# export data for playing around with\n\nrio::export(CRAN_pkgs, here(\"datasets\", \"CRAN_pkgs.rds\"))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}