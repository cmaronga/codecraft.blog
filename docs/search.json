[
  {
    "objectID": "publications/publications.html#authored-conference-papers",
    "href": "publications/publications.html#authored-conference-papers",
    "title": "Maronga CodeCraft Blog",
    "section": "Authored conference papers",
    "text": "Authored conference papers"
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html",
    "href": "posts/celebrate-100-gym-days/index.html",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "",
    "text": "Because I can exercise and share a brief story!"
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html#introduction",
    "href": "posts/celebrate-100-gym-days/index.html#introduction",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "Introduction",
    "text": "Introduction\nWelcome to the journey of celebrating 100 days of unwavering dedication to my fitness regimen. Beginning of the year, I embarked on a quest for personal betterment, focusing on gym weight-lifting and outdoor running exercises, with a target of achieving at least 11 kilometers each weekend (fun fact: I exceeded my goal by running approximately 28 kilometers in just about two weekends).\nThis journey culminated in a staggering 100 days of sheer hard work, unwavering dedication, and a growing passion for all things fitness. In this article, I aim to take you through this transformative 100-day journey, sharing the challenges I overcame, and the invaluable lessons I’ve learned along the way.\n\n# Load packages for session\npacman::p_load(\n  lubridate,   # handle and manage dates\n  flextable,   # for quick and neat tables\n  ggthemes,    # ggplot2 themes extension\n  here,        # manage file paths\n  rio,         # data import\n  scales,      # for the date label function\n  tidyverse    # data wrangling and viz\n)\n\n# set theme for ggplot2\ntheme_set(\n  theme_hc(base_size = 18) +                  # base size\n    theme(\n      legend.position = \"none\",              # No legend, unless specified in the plot\n      legend.title = element_blank(),         # No title on the legend\n      axis.title.y = element_text(angle = 90) # spin y title 90 degrees\n    )\n)\n\nThe below code below utilize the tribble function to create row-wise tibble of the workout data for the months beggining January 2023 to my celebration month and date.\nI also import an excel log (from the gym logs) capturing start and end times for all the gym workouts for the months listed. This will be used to create interesting visualization later on.\n\n# Creating tibble for monthly workout counts\n# used to visualize in the latter sections\nworkout_df &lt;- tribble(\n  ~ month, ~n_workouts,\n  \"2023-01\", 14 ,\n  \"2023-02\", 13,\n  \"2023-03\",05 ,\n  \"2023-04\", 0,\n  \"2023-05\",02 ,\n  \"2023-06\",14 ,\n  \"2023-07\", 23,\n  \"2023-08\", 15,\n  \"2023-09\",0 ,\n  \"2023-10\", 14\n)\n\n# import gym logs\ngym_log_raw &lt;- import(here(\"posts\",\"celebrate-100-gym-days\", \"chris-gym_game.xlsx\"))\n\n# data processing\nworkout_df &lt;- workout_df %&gt;% \n  mutate(\n    month = ym(month),\n    n_workouts = as.integer(n_workouts)\n  )"
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html#cleaning-gym-logs-data",
    "href": "posts/celebrate-100-gym-days/index.html#cleaning-gym-logs-data",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "Cleaning gym logs data",
    "text": "Cleaning gym logs data\n\n# clean the gym log data\ngym_log &lt;- gym_log_raw %&gt;% \n  \n  # create visit date, stat time and end time\n  mutate(\n    visit_start_time  = str_extract(visit_start, \"\\\\d+:\\\\d+[aApP][mM]\"),       # extract time component\n    visit_end_time    = str_extract(visit_end, \"\\\\d+:\\\\d+[aApP][mM]\"),         # extract time component\n    visit_date        = str_extract(visit_start, \"\\\\d{2} [A-Za-z]{3} \\\\d{2}\"), # extract date component\n    visit_date        = dmy(visit_date),                                       # convert into ISO date\n    week_day          = wday(visit_date, label = T, abbr = T),                 # day of the week\n    month             = month(visit_date, label = T),                          # workout month\n    duration_mins     = as.integer(str_remove(duration, \" minutes\")),          # minutes in the gym\n    morning_wkout     = ifelse(str_detect(visit_start, \"am\"), \"Yes\", \"No\")     # Morning workout (Yes/No)\n  ) %&gt;% \n  \n  # drop the first 3 columns, not neede downstream\n  select(-c(1:3)) %&gt;% \n  arrange(visit_date)\n\ngym_log %&gt;% select(-gym_game) %&gt;% head(n = 8) %&gt;% \n  flextable()\n\n\nvisit_start_timevisit_end_timevisit_dateweek_daymonthduration_minsmorning_wkout10:47am11:40am2023-01-02MonJan53Yes4:56pm6:12pm2023-01-03TueJan76No5:21pm6:37pm2023-01-04WedJan76No1:49pm3:26pm2023-01-08SunJan97No8:11pm9:23pm2023-01-09MonJan72No8:16pm9:28pm2023-01-10TueJan72No7:45pm9:04pm2023-01-11WedJan79No6:22am7:48am2023-01-13FriJan86Yes\n\n\nMy journey commenced with setting realistic and achievable fitness goals, providing me with a clear path and unwavering focus. My objectives included:-\n\nEnhancing full-body muscle strength\nBuild endurance\nOverall fitness\n\nMy workout routine was marked by monthly fluctuations, and I visualized these trends to identify both my best and most challenging months.\n\nworkout_df %&gt;%\n  ggplot(aes(x = month, y = n_workouts, group = 1)) +\n  geom_point(aes(size = n_workouts)) +   # size of point depends on number of workouts\n  geom_line(linewidth = 0.8) +\n  labs(title = \"Trend of monthly gym workouts\",\n       subtitle = \"Past 10 months only\",\n       x = \"Month\", y = \"No. of workouts\") +\n  scale_x_date(date_breaks = \"month\",    # break by 1 month interval\n               date_labels = \"%b\")       # show only month of the year\n\n\n\n\nFigure 1: Monthly Gym workouts\n\n\n\n\nFigure 1 shows a trend of monthly workouts, with my worst efforts in the months of March and May (I have an excuse though 😂). I reached by best efforts in the month of July with a total of 23 gym works in that monthly only 😰, never managed to replicate that effort, it has now since become my other additional goal, you see how it works now?\n\nworkout_df %&gt;%\n  ggplot(aes(y = n_workouts, x = factor(1))) +\n  geom_boxplot(width = 0.2) +\n  labs(title = \"The overal picture\",\n       x = \"\", y = \"No. of workouts\") +\n  theme(axis.text.x = element_blank())\n\n\n\n\nFigure 2: Workout summary\n\n\n\n\nI averaged 10 workouts per month during the 10 months period (despite registering 0 in April and May) Figure 2. I registered a median of 13 workouts per month, not bad for a beginner though, proud of these numbers to the greatest heights."
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html#sec-monthviz",
    "href": "posts/celebrate-100-gym-days/index.html#sec-monthviz",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "Monthly Visual Chart",
    "text": "Monthly Visual Chart\nThe cascede images below shows monthly presence in the gym. The light-green highlighted dates represents the days I worked out for that month. July has a good pattern, I love it 🤗\n\n\n\n\n\n\nJan\n\n\n\n\n\n\n\nFeb\n\n\n\n\n\n\n\nMar\n\n\n\n\n\n\n\nApr\n\n\n\n\n\n\n\nMay\n\n\n\n\n\n\n\n\n\nJun\n\n\n\n\n\n\n\nJul\n\n\n\n\n\n\n\nAug\n\n\n\n\n\n\n\nSept\n\n\n\n\n\n\n\nOct"
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html#workout-schedule-structuring-success",
    "href": "posts/celebrate-100-gym-days/index.html#workout-schedule-structuring-success",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "Workout schedule: Structuring Success",
    "text": "Workout schedule: Structuring Success\nA structured workout schedule was instrumental in maintaining consistency. It included various exercises targeting different muscle groups and allocated specific times to each.\n\n# Work out schedule\nworkout_sched &lt;- tribble(\n  ~ Day, ~ `50 mins`, ~ `30 mins`, ~`10 mins`,\n  \"Monday\", \"Chest\", \"Biceps\", \"Treadmill Run\",\n  \"Tuesday\", \"Back\", \"Triceps\", \"Treadmill Run\",\n  \"Wednesday\", \"Legs\", \"Shoulder\", \"Treadmill Run\",\n  \"Thursday\", \"Core\", \"Compound exercises\", \"Treadmill Run\",\n  \"Friday\", NA_character_, NA_character_, \"Rest day (Not always)\",\n  \"Saturday\", NA_character_, NA_character_, \"Outdoor half-marathon 11 - 13kms\")\n\nThe table below shows the daily work-out schedule, making sure I spend more time on muscles that take long to grow and always end my workout with a 10 mins run on the treadmill. The headers are day of the week and mins allocated to each exercise.\n\nworkout_sched %&gt;% \n  qflextable()\n\n\n\nTable 1:  Workout schedule Day50 mins30 mins10 minsMondayChestBicepsTreadmill RunTuesdayBackTricepsTreadmill RunWednesdayLegsShoulderTreadmill RunThursdayCoreCompound exercisesTreadmill RunFridayRest day (Not always)SaturdayOutdoor half-marathon 11 - 13kms\n\n\n\nAs a starting point, I aimed at working out for at least 1hr 30 mins; focusing two muscles a day as shown in Table 1. Friday was not all rest day as can been seen in monthly visual chart - 3, but was mostly a plan to catch up on missed appointment a.k.a punish yourself for missing many sessions the prior month."
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html#visualizing-progress-tracking-transformations",
    "href": "posts/celebrate-100-gym-days/index.html#visualizing-progress-tracking-transformations",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "Visualizing Progress: Tracking Transformations",
    "text": "Visualizing Progress: Tracking Transformations\nVisualizing my workout data unveiled the trends in my workout duration, enabling me to track improvements and shifts in my routine.\n\nAverage monthly workout duration\n\ngym_log %&gt;% \n  group_by(month) %&gt;% \n  summarise(\n    avg_dur = mean(duration_mins)\n  ) %&gt;% \n  ggplot(aes(x = month, y = avg_dur, group = 1)) +\n  geom_line()+\n  geom_point() +\n  labs(\n    title = \"Monthly average workout duration in minutes\",\n    x = \"Month\",\n    y = \"duration (mins)\"\n  )\n\n\n\n\nFigure 3: Average workout duration\n\n\n\n\nThe month of June was my worst solo effort, but this trend shows the significance of my gym buddy the month of after June and the average stay and working out in the gym that shot up by approximately 38% and almost stabilized. I can only hope for an upward trend going forward.\n\n\nTrend - best month\nThe month after getting a workout buddy was the best. All metrics were at their all time best i.e. more days in the gym, more time working out for the days designated; and in fact, the second best monthly average workout duration this year Figure 3. This once again tells the importance of the incoming energy, support, encouragement and accountability from my workout buddy.\n\n# create metrics for dynamic labeling\ntot_mins &lt;- gym_log %&gt;% filter(month == \"Jul\") %&gt;% \n  select(duration_mins) %&gt;% pluck() %&gt;% sum()\n\n# days worked\ndays_work &lt;- gym_log %&gt;% filter(month == \"Jul\") %&gt;% nrow()\n \n\ngym_log %&gt;% \n  filter(month == \"Jul\") %&gt;% \n  ggplot(aes(x = visit_date, y = duration_mins, group = 1)) + \n  geom_point()+\n  geom_line() +\n  scale_x_date(date_breaks = \"2 days\",    # break by 1 month interval\n               #date_labels = \"%d\\n%b\",\n               labels = label_date_short()) +       # show only month of the year\n  labs(x = \"Date\", y = \"duration(mins)\",\n       title = \"Trend of best effort, July 2023\",\n       caption = str_glue(\"Days working out = {days_work}\\nTotal mins = {comma(tot_mins)}\"))\n\n\n\n\nFigure 4: Dialy work out trend, July 2023\n\n\n\n\n\n\nSummary of workout days:Evolution of Dedication\nIn general, my working out routine greatly improved months following June and this can all be attributed to having a workout buddy. The box plots below paint a picture of a transformation in the process; which can only get better with time. Amidst all the fired up effort, I missed a few days/months; but that’s a story for another day of why that happened.\n\ngym_log %&gt;% \n  ggplot(aes(x = month, y = duration_mins)) +\n  geom_boxplot(width = 0.5, outlier.color = \"red\") +\n  labs(y = \"duration(mins)\")\n\n\n\n\nFigure 5: Summary of monthly workouts\n\n\n\n\nSummarizing my monthly workouts using box plots revealed the distribution of my workout durations and provided further insights into my fitness journey Figure 5.\n\n\nHistogram of workout duration\nA histogram of workout duration showcases the diverse nature of my exercise routines, with both short, intense sessions and longer, endurance-based workouts.\nI am proud of every value on the x-axis and how many times it occurred on the y-axis. I don’t want to settle on the middle ground but I lik the extremes because they come into play when circumstance prevail.\n\ngym_log %&gt;% \n  ggplot(aes(x = duration_mins)) +\n  geom_histogram(fill = \"steelblue\") +\n  labs(x = \"duration(mins)\", y = \"Frequency\",\n       title = \"Histogram of all-time workout duration\",\n       subtitle = \"Jan upto Oct 2023\")\n\n\n\n\nFigure 6: Histogram of all-time workout duration"
  },
  {
    "objectID": "posts/celebrate-100-gym-days/index.html#conclusion-and-take-aways",
    "href": "posts/celebrate-100-gym-days/index.html#conclusion-and-take-aways",
    "title": "Celebrating 100 days of Gym dedication",
    "section": "Conclusion and take aways",
    "text": "Conclusion and take aways\nThis celebration is about a habit I have managed to pick, the growth and the transformation it has brought about.This type of a journey requires accountability, and for that reason, I have a workout buddy Tony Henry who I am accountable to, and the gym app was very crucial in tracking my progress.\nFitness journey comes with challenges, for instance having to wake up in the morning at around 6am to workout while you would rather keep warm and sleep is the hardest choice. Overcoming this type of challenge was key to my success, made me mentally stronger and enabled me to become more resilient.\nListen to your body always, know when to push harder and when to rest. Celebrate every milestone you have achieved, even if it meant you lifted 2.5kg extra on top of your regular weight limit. Celebrations makes you more energetic and looking forward to move up next level the following workout day.\nI hope my story inspires you to start your fitness journey or continue the one you already archived. It’s doable, if you put mind to it. Here is to 100 days of hard-work, dedication and determination 🙌🥳."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Maronga CodeCraft Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n  \n\n\n\n\ndplyr::coalesce() in action\n\n\n\n\n\n\n\n\n\n\n\n\n2023-10-27\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\nCelebrating 100 days of Gym dedication\n\n\n\n\n\n\n\n\n\n\n\n\n2023-10-24\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nWorking with Databases in R\n\n\n\n\n\n\n\n\n\n\n\n\n2021-06-12\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nAutomating Clinical Data Management\n\n\n\n\n\n\n\n\n\n\n\n\n2018-12-16\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Maronga CodeCraft Blog",
    "section": "",
    "text": "My name is Christopher Maronga, I hail from the beautiful landscapes of Kenya, East Africa.\nI have a wealth of experience managing and analysing healthcare data for decision-making, as well as teaching introductory and advanced courses in R.\nI’m passionate about reproducible research, automating data products, statistical computing, and data visualization."
  },
  {
    "objectID": "about.html#bio",
    "href": "about.html#bio",
    "title": "Maronga CodeCraft Blog",
    "section": "",
    "text": "My name is Christopher Maronga, I hail from the beautiful landscapes of Kenya, East Africa.\nI have a wealth of experience managing and analysing healthcare data for decision-making, as well as teaching introductory and advanced courses in R.\nI’m passionate about reproducible research, automating data products, statistical computing, and data visualization."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Maronga CodeCraft Blog",
    "section": "Education",
    "text": "Education\n\nMSc. Statistical Sciences |Strathmore University\nBSc. in Mathematics |JKUAT"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Maronga CodeCraft Blog",
    "section": "Experience",
    "text": "Experience\n\nPhase II & IV CTs\nReal World Data/Real World Evidence\nHealth Research\nData Management/Wrangling\nData Analysis/Statistical Analysis\nPredictive Modelling"
  },
  {
    "objectID": "about.html#skillslanguages",
    "href": "about.html#skillslanguages",
    "title": "Maronga CodeCraft Blog",
    "section": "Skills/languages",
    "text": "Skills/languages\n\nR Programming/RShiny\nPython\nSQL/MySQL\nREDCap\nGit/GitHub\nLaTeX\nDocker"
  },
  {
    "objectID": "about.html#workshops-delivered",
    "href": "about.html#workshops-delivered",
    "title": "Maronga CodeCraft Blog",
    "section": "Workshops delivered",
    "text": "Workshops delivered\n\nWorking with Databases in R @ RLadies Nairobi\nWorking with Databases in R @ NHS-R COnference\nIntroduction to Data Management in R @satRday Nairobi\nIntegrating Rshiny and REDCap for Data Management @Why R Conference\nIntroduction to data structures in R@ Ai Kenya Code Maktaba"
  },
  {
    "objectID": "posts/automating-data-management/index.html",
    "href": "posts/automating-data-management/index.html",
    "title": "Automating Clinical Data Management",
    "section": "",
    "text": "Using REDCap, MySQL, RShiny-server"
  },
  {
    "objectID": "posts/automating-data-management/index.html#introduction",
    "href": "posts/automating-data-management/index.html#introduction",
    "title": "Automating Clinical Data Management",
    "section": "Introduction",
    "text": "Introduction\nData management in multi-centre cohort studies presents unique challenges, particularly when these study sites are widely dispersed geographically and possess varying levels of technical and human resources. It is crucial to maintain data quality, promptly address data inconsistencies, and generate timely progress reports. This is especially true for initiatives like the Childhood Acute Illness and Nutrition Network (CHAIN), which involved recruiting participants from nine hospitals located in Africa and Asia. The CHAIN study collected highly detailed data spanning various biological and social domains."
  },
  {
    "objectID": "posts/automating-data-management/index.html#methods",
    "href": "posts/automating-data-management/index.html#methods",
    "title": "Automating Clinical Data Management",
    "section": "Methods",
    "text": "Methods\nTo streamline data management processes, the CHAIN cohort employed Research Electronic Data Capture (REDCap), a web-based, open-source database driven by metadata. In this article, I describe our effective utilization of REDCap in combination with the open-source R software to automate the data management workflow for the CHAIN study. I aim to document, step by step, the various decisions and implementations that were instrumental in this process. I plan to make this information available on my webpage for others to read and implement, although this will require a few days to compile and potentially create informative infographics.\nAdditionally, I had the opportunity to present this work at the Why R conference in 2021, and you can watch the presentation on YouTube. The presentation slides are also accessible here for download\nI hope after watching the conference presentation, you shall an idea how this was set up. I am working toward presenting this work as a guideline, untill then, pleas be patient and if you have any questions, feel free to reach me via e-mai."
  },
  {
    "objectID": "posts/coalesce-in-action/index.html",
    "href": "posts/coalesce-in-action/index.html",
    "title": "dplyr::coalesce() in action",
    "section": "",
    "text": "Viable shortcut to missing-value-free data set"
  },
  {
    "objectID": "posts/coalesce-in-action/index.html#introduction",
    "href": "posts/coalesce-in-action/index.html#introduction",
    "title": "dplyr::coalesce() in action",
    "section": "Introduction",
    "text": "Introduction\nMissing data can be a major headache when handling data in R; more especially if these NA’s are scattered across multiple columns representing your one variable of interest.\nThe coalesce() function from dplyr package comes in handy in such situations. In this short article, I am going to show you how powerful the function coalesce() is and how it can make your data manipulation task easy. To put in perspective, the function extracts the first non-missing (non-NA) value from a set of columns or values, making your data cleaner and analysis-ready, it does this by prioritizing a designated column as we will see from the worked out examples below."
  },
  {
    "objectID": "posts/coalesce-in-action/index.html#create-fictious-data",
    "href": "posts/coalesce-in-action/index.html#create-fictious-data",
    "title": "dplyr::coalesce() in action",
    "section": "Create fictious data",
    "text": "Create fictious data\n\n# load packages\npacman::p_load(\n  tidyverse,\n  flextable\n)\n\n# Create fictitious data\nfict_data &lt;- tribble(\n ~PTID, ~ HT_ADM, ~ HT_DISCH, ~ HT_D45, ~ HT_D90,       # patient ID and Height measurements at different time-points\n  \"7001\",    100,      100.1,        100,       NA_real_,\n  \"7002\",    97,       98,         NA_real_,  97.5,\n  \"7003\",    97.6,     NA_real_,    97,      97.5,\n  \"7004\",    NA_real_,  99,        99.8,     100,\n  \"7005\",    79.5,  NA_real_,   78.9,     NA_real_,\n  \"7006\",    NA_real_,  NA_real_,   NA_real_,  102.1,\n  \"7007\",    78.5,      79,         NA_real_,    NA_real_,\n  \"7008\",    NA_real_,      98,        98,       NA_real_)\n\n\n# qflextable-it\nfict_data %&gt;% \n  qflextable()\n\n\n\nTable 1:  Ficticious patient data PTIDHT_ADMHT_DISCHHT_D45HT_D907001100.0100.1100.0700297.098.097.5700397.697.097.5700499.099.8100.0700579.578.97006102.1700778.579.0700898.098.0\n\n\n\nThe data in Table 1 is a made up one, representing height measurements of 8 patients across 4 time-points i.e during admission, discharge, day 45 and day 90 follow up visits respectively. As you can see, there is no single column with complete data. The assumption is that the measurement are subject to some absolute error and therefore any column can be used as measured height in an analysis; the problem is that no column is complete and this is what we are going to tackle using coalesce()"
  },
  {
    "objectID": "posts/coalesce-in-action/index.html#creating-height-column",
    "href": "posts/coalesce-in-action/index.html#creating-height-column",
    "title": "dplyr::coalesce() in action",
    "section": "Creating Height column",
    "text": "Creating Height column\nThe aim is to use coalesce() to create a column HT_cm with non-missing data using. We can try a few combination, but I am confident that if you look carefully, there are probably a few combination of two columns that can give you that.\nNOTE: This is an illustration of how coalesce() works, your use-case might be different, just think how this function fits in.\n\nHT_ADM vs HT_D90\nHere coalesce() gives priority to HT_ADM and if this column has some NA’s while HT_D90 has values in the same row; the values of HT_D90 get pulled/filled in place of NA’s to form HT_CM.\n\nfict_data %&gt;% \n  mutate(\n    HT_CM = coalesce(HT_ADM, HT_D90)    # prioritize _ADM over _D90\n  ) %&gt;% \n  flextable()\n\n\nPTIDHT_ADMHT_DISCHHT_D45HT_D90HT_CM7001100.0100.1100.0100.0700297.098.097.597.0700397.697.097.597.6700499.099.8100.0100.0700579.578.979.57006102.1102.1700778.579.078.5700898.098.0\n\n\nBut we still have one more missing value for patient 7008\n\n\nHT_ADM vs HT_DISH\nTake a combination of measurement at admission and discharge for instance.\n\nfict_data %&gt;% \n  mutate(\n    HT_CM = coalesce(HT_ADM, HT_DISCH) # prioritize _ADM over _DISCH\n  ) %&gt;% \n  flextable()\n\n\nPTIDHT_ADMHT_DISCHHT_D45HT_D90HT_CM7001100.0100.1100.0100.0700297.098.097.597.0700397.697.097.597.6700499.099.8100.099.0700579.578.979.57006102.1700778.579.078.5700898.098.098.0\n\n\nSame problem, we still have a missing cell for patient 7006 on the HT_CM column\n\n\nHT_D90 vs HT_DISCH\nWe can reverse the natural order of the visits and the logic still remains. In the below example, coalesce() prioritizes HT_D90 over HT_DISCH but we still end up a missing cell in patient 7005 since both measurements are NA at discharge and at day 90.\n\nfict_data %&gt;% \n  mutate(\n    HT_CM = coalesce(HT_D90, HT_DISCH)   # prioritize _D90 over _DISCH\n  ) %&gt;%  \n  flextable()\n\n\nPTIDHT_ADMHT_DISCHHT_D45HT_D90HT_CM7001100.0100.1100.0100.1700297.098.097.597.5700397.697.097.597.5700499.099.8100.0100.0700579.578.97006102.1102.1700778.579.079.0700898.098.098.0\n\n\n\n\nUse all columns\nThe ideal is to use all the columns. coalesce() prioritizes form “left to right” (in this case HT_ADM) filling in the missing cells on the left with the first non-missing value it encounters to the right. This is how it takes care of the non-missing business in your data.\n\nfict_data %&gt;% \n  mutate(\n    HT_CM = coalesce(HT_ADM, HT_DISCH, HT_D45, HT_D90)\n  ) %&gt;% \n  flextable()\n\n\nPTIDHT_ADMHT_DISCHHT_D45HT_D90HT_CM7001100.0100.1100.0100.0700297.098.097.597.0700397.697.097.597.6700499.099.8100.099.0700579.578.979.57006102.1102.1700778.579.078.5700898.098.098.0"
  },
  {
    "objectID": "posts/working-with-databases/index.html",
    "href": "posts/working-with-databases/index.html",
    "title": "Working with Databases in R",
    "section": "",
    "text": "MySQL, SQLite, R\nThis blog post comes as a follow-up to a successful online training session jointly organized by NairobiR and RLadies on June 12, 2021. If you missed the session, you can view the recording on this YouTube link\nIn both the video and this accompanying blog, I delve into the fundamental principles of establishing dynamic connections and extracting data from databases using Application Programming Interfaces (APIs). Regardless of how and where data is stored, the initial step in any data management process involves loading it into your preferred working tool.\nRelational databases, such as RMySQL, and web-based databases, like REDCap, have gained popularity for efficiently and cost-effectively managing small to medium-sized datasets. In this blog, I’ll guide you through the essential steps to access and utilize data stored in these platforms using the R statistical language. I will provide practical examples to demonstrate:\n\nEstablishing an efficient connection between R and Relational Database Management Systems (RDBMS).\nQuerying data housed in any RDBMS directly from within R/RStudio.\nConnecting to and querying data from a Research Electronic Data Capture (REDCap) database.\nBest practices for securing your API while collaborating on projects.\n\nPlease note that this blog is a work in progress. In the meantime, you can access the workshop slides for reference here and the youtube link should be resourceful since this was a live coding exercise.\nI also delivered a similar workshop at NHS-R conference in 2022, the workshop materials can be found here, while the recorded workshop video can be accessed in this YouTube link."
  }
]